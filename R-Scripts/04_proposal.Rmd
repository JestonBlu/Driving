---
title: "Distracted Driving Data Analysis Proposal"
author: "Joseph Blubaugh"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document:
    latex_engine: xelatex
    highlight: pygments
mainfont: DejaVu Sans Mono
sansfont: DejaVu Sans Mono
fontsize: 11pt
geometry: margin=1in
---

```{r setup, echo=FALSE}

library(knitr)
library(ggplot2)
library(plyr)
library(reshape2)
library(pander)

load(file = "../R-Data/faces.rda")

```

# Data

The data in this project are of 8 driving simulations for 66 individuals ranging from 3,000 to 30,000 observations per simulation. There are over 6.7 million observations in the entire dataset. The data from each simulation includes likelihood scores for 8 facial expressions recorded at a fixed interval of .03 seconds. Stimuli data which records targetted events that were introduced into each simulation and basic demographic data on each subject are also available.

```{r dta, echo=FALSE, comment=NA, results='asis'}
set.alignment('left')
x = head(faces[, c(1,4,5,9,7,11:17)])
x[, 5:12] = apply(x[, 5:12], 2, function(x) round(x, 3))
pander(x, style = 'rmarkdown', caption = "Combined Simulation and Stimuli Datasets", split.table = Inf)
```

There were several misspelled descriptions in the stimuli files so I reconstructed the event names. At least one of the events appears to be miscoded. There is only one simulation in trial 006 that has a Mathematical Question event. This appears to be miscoded and should probably be coded as Emotional Question instead. 

```{r tab1, echo=FALSE, comment=NA, results='asis'}

x = dcast(ddply(stats, .(Trial, Event), summarise, count = length(Subject)), 
      Event ~ Trial, value.var = "count")
x[is.na(x)] = 0
x$Event = relevel(x$Event, ref = "No Event")
kable(arrange(x, Event), caption = "Count of Simulations by Event Type")

```

The published literature on this data showed evidence that texting and driving contributes significantly to poor driving performance. Driving performance data is unavailable in this analysis.

# Analysis Proposal

The plot below shows the output of two driving simulations for a single subject (T086), one with no events (Sim 004), and one with texting events (Sim 007). While we do not know the subject's driving performance in any of the simulations, it is clear to see that there are changes in the subject's facial expressions during the texting events compared to the driving simulation where no events occur.

```{r graph1, echo=FALSE, comment=NA, fig.width=8, fig.height=6}

x = subset(faces, Trial == '007' | Trial == '004')
x = melt(x, id.vars = c("Subject", "Age", "Gender", "Time", "Event", "Event.Switch", "Trial"),
         measure.vars = c("Anger", "Contempt", "Disgust", "Fear", "Joy", 
                          "Sad", "Surprise", "Neutral"))
## Old Female
ggplot(subset(x, Subject == 'T086'), aes(x = Time, y = value, group = Trial, color = Event)) +
  geom_point(alpha = .03) +
  geom_smooth(size = .2, aes(color = Trial))+
  scale_color_manual("", labels = c("Sim 004 (Driving)", "Sim 007 (Texting & Driving)", "Not Texting", "Texting"), 
                     values = c("blue", "red", "gray50", "#f0b823")) +
  scale_x_continuous("Seconds") +
  scale_y_continuous("Emotional Likelihood", breaks = c(0, .5, 1)) +
  facet_wrap(~variable) +
  guides(colour = guide_legend(override.aes = list(alpha = 1, size = 1))) +
  ggtitle("Subject T086 (Old Female)\nSim 004 (Driving) and Sim 007 (Driving and Texting)") +
  theme(legend.position = "bottom")


```

I propose that this analysis focus on building a model to detect whether the subject is texting or otherwise distracted based on demographics and changes in facial expressions. I would also like to leave in the time series component and experiment with complex models such as neural nets or support vector machines. I am particularly interested in measuring the similarities in facial expression changes based on encountered events. I would also like to understand if one model performs reasonably well on all or most subjects, or are the subjects so unique that only individual models would perform well.


