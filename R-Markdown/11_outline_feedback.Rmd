---
title: "Response to Feedback"
author: "Joseph Blubaugh"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document:
    fig_height: 3.5
    highlight: pygments
    latex_engine: xelatex
mainfont: DejaVu Sans Mono
sansfont: DejaVu Sans Mono
fontsize: 11pt
geometry: margin=1in
---

#### **Why not use ROC curves to graphically compare model performance?**

I did not think about this at all, but I think its a great idea.

![ROC Plot 1](../Presentation/Plots/ROC1.png)
![ROC Plot 2](../Presentation/Plots/ROC2.png)

##### Model Performance

| Model         | Data Processing      | Data Split     | MaxItr  | Size   | Decay   | Training | Testing  | AUC      |
|:--------------|:---------------------|:---------------|:--------|:-------|:--------|:---------|:---------|:---------|
| Model 1:      | Original             | 365 Split      | 100     | 50     | .10     | .776     | .693     | .754     |
| Model 2:      | Original             | Entire Sim     | 100     | 50     | .20     | .766     | .766     | .862     |
| Model 3:      | Differencing         | 365 Split      | 100     | 25     | .10     | .538     | .529     | .556     |
| Model 4:      | Differencing         | Entire Sim     | 100     | 25     | .10     | .548     | .548     | .610     |
| Model 5:      | Moving Avg           | 365 Split      | 100     | 10     | .00     | .503     | .503     | .530     |
| Model 6:      | Moving Avg           | Entire Sim     | 100     | 10     | .00     | .524     | .524     | .573     |
| Model 7:      | 1/2 Sec Cut          | 365 Split      | 100     | 50     | .10     | .819     | .694     | .766     |
| **Model 8:**  | **1/2 Sec Cut**      | **Entire Sim** | **100** | **50** | **.10** | **.801** | **.789** | **.881** |
| Model 9:      | 1/2 Sec Diff         | 365 Split      | 100     | 25     | .00     | .664     | .631     | .683     |
| Model 10:     | 1/2 Sec Diff         | Entire Sim     | 100     | 50     | .00     | .500     | .500     | .486     |
| Model 11:     | 1/2 Sec Cut Stat     | 365 Split      | 100     | 50     | .10     | .855     | .727     | .795     |
| **Model 12:** | **1/2 Sec Cut Stat** | **Entire Sim** | **100** | **50** | **.20** | **.833** | **.815** | **.900** |

\newpage

##### Further Training Best Models

| Model        | Data Processing  | Data Split     | MaxItr   | Size   | Decay   | Training | Testing  | AUC      |
|:-------------|:-----------------|:---------------|:---------|:-------|:--------|:---------|:---------|:---------|
| Model 8:     | 1/2 Sec Cut      | Entire Sim     | 250      | 50     | .10     | .844     | .825     | .907     |
| Model 8:     | 1/2 Sec Cut      | Entire Sim     | 500      | 50     | .10     | .847     | .825     | .911     |
| **Model 8:** | **1/2 Sec Cut**  | **Entire Sim** | **1000** | **50** | **.10** | **.853** | **.828** | **.917** |
| Model 12:    | 1/2 Sec Cut Stat | Entire Sim     | 250      | 50     | .10     | .872     | .837     | .915     |
| Model 12:    | 1/2 Sec Cut Stat | Entire Sim     | 500      | 50     | .20     | .880     | .839     | .912     |
| Model 12:    | 1/2 Sec Cut Stat | Entire Sim     | 1000     | 50     | .10     | .900     | .840     | .913     |



##### Balanced Accuracy by Subject


| &nbsp;         | T022  | T035  | T086  | T083  | T074  | T018  | T007  | T006  | T020  | T088  | T012  | T032  | T044  | T009  | T064  | T003  | T011  | T082  | T060  | **Top**  |
|:---------------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:---------|
| **Train**      | 0.976 | 0.956 | 0.970 | 0.946 | 0.934 | 0.930 | 0.950 | 0.953 | 0.929 | 0.921 | 0.926 | 0.893 | 0.926 | 0.915 | 0.940 | 0.887 | 0.894 | 0.902 | 0.904 | **.921** |
| **Test**       | 0.964 | 0.945 | 0.943 | 0.936 | 0.933 | 0.927 | 0.924 | 0.922 | 0.921 | 0.910 | 0.904 | 0.902 | 0.900 | 0.898 | 0.895 | 0.885 | 0.884 | 0.882 | 0.880 | **.913** |
| **GenderMale** | 0     | 0     | 0     | 1     | 1     | 0     | 1     | 0     | 0     | 1     | 0     | 1     | 1     | 1     | 0     | 1     | 1     | 1     | 0     | **10**   |
| **AgeOld**     | 0     | 1     | 1     | 1     | 1     | 0     | 0     | 0     | 0     | 1     | 0     | 1     | 1     | 0     | 0     | 0     | 0     | 0     | 0     | **7**    |


| &nbsp;         | T013  | T081  | T080  | T016  | T079  | T051  | T039  | T015  | T046  | T066  | T076  | T010  | T005  | T008  | T042  | T024  | T077  | T001  | T029  | **Middle** |
|:---------------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:-----------|
| **Train**      | 0.911 | 0.954 | 0.893 | 0.881 | 0.888 | 0.816 | 0.883 | 0.881 | 0.871 | 0.851 | 0.856 | 0.843 | 0.859 | 0.868 | 0.840 | 0.797 | 0.796 | 0.850 | 0.816 | **.860**   |
| **Test**       | 0.878 | 0.877 | 0.873 | 0.869 | 0.860 | 0.855 | 0.851 | 0.848 | 0.839 | 0.838 | 0.830 | 0.827 | 0.824 | 0.820 | 0.817 | 0.807 | 0.806 | 0.797 | 0.790 | **.832**   |
| **GenderMale** | 1     | 1     | 0     | 0     | 0     | 1     | 0     | 1     | 1     | 0     | 1     | 0     | 1     | 0     | 1     | 0     | 0     | 1     | 0     | **9**      |
| **AgeOld**     | 0     | 0     | 0     | 0     | 0     | 1     | 1     | 0     | 1     | 0     | 1     | 0     | 0     | 0     | 1     | 0     | 1     | 0     | 1     | **6**      |


| &nbsp;         | T017  | T014  | T054  | T031  | T040  | T061  | T033  | T019  | T021  | T036  | T084  | T004  | T073  | T002  | T041  | T025  | T047  | T034  | **Bottom** |
|:---------------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:------|:-----------|
| **Train**      | 0.784 | 0.805 | 0.803 | 0.788 | 0.792 | 0.787 | 0.776 | 0.738 | 0.764 | 0.785 | 0.804 | 0.722 | 0.749 | 0.730 | 0.707 | 0.758 | 0.719 | 0.669 | **.760**   |
| **Test**       | 0.783 | 0.782 | 0.762 | 0.753 | 0.752 | 0.747 | 0.742 | 0.739 | 0.728 | 0.722 | 0.718 | 0.715 | 0.703 | 0.694 | 0.691 | 0.689 | 0.665 | 0.638 | **.723**   |
| **GenderMale** | 1     | 0     | 1     | 0     | 1     | 1     | 0     | 1     | 1     | 1     | 1     | 0     | 0     | 0     | 0     | 0     | 0     | 1     | **9**      |
| **AgeOld**     | 0     | 0     | 1     | 1     | 1     | 0     | 1     | 0     | 0     | 1     | 1     | 0     | 1     | 0     | 1     | 1     | 1     | 1     | **11**     |

###### Summarised Accuracy by Subject

|            | Male  | Female |  Old  | Young | Young Male | Young Female | Old Male | Old Female |
|:-----------|:-----:|:-------|:-----:|:------|:-----------|:-------------|:--------:|:----------:|
| **Top**    | 35.7% | 32.1%  | 29.1% | 37.5% | 35.7%      | 41.1%        |  35.7%   |    9.1%    |
| **Middle** | 32.1% | 35.7%  | 25.0% | 40.6% | 35.7%      | 41.1%        |  28.5%   |   36.3%    |
| **Bottom** | 32.1% | 32.1%  | 45.8% | 21.8% | 28.5%      | 17.6%        |  35.7%   |   54.5%    |



* 13 of 56 had testing performance > 90%
* 36 of 56 had testing performance > 80%
*  5 of 56 had testing performance < 70%
*  5 of the 6 worst performaning Subjects were Old (1 Male, 4 Female)


#### **Are you trying to detect whether texting occurred during a given interval or a single observation?**

Initially I was looking at individual observations, but as I tried different approaches I ended up aggregating the data and found those models to be the best performing.

#### **Baselining: What is the purpose?**

My goal was to remove the effect of the simulation from the texting trial. The simulations involved active traffic and a detour which each driver had to navigate. Since trial 4 was identical to trials 5, 6, and 7 minus the events that took place, it seemed like the natural choice.

#### **Why do you say there was evidence that one size fits all model will not work?**

At this stage I was aggregating data at the subject level by event and I think the range of values were all over the place which prevented the models I tried from being any good. I proposed that adding a factor variable for subject would allow me to model individuals driving behavior that might be more successful at detecting texting.

#### **On Time omission -- why not include lagged variables?**

In retrospect this probably would have been a good thing to try. The farthest I went looking into time series was trying differencing which ended up being the worst of all of the methods I experimented with.

#### **Does including age and gender as well as Subject in the model cause problems due to collinerity?**

I mainly included included age and gender so that there were parameters availble to account for universal age and gender effects, if there were any. I dont think there is an issue with collinerity because Im not inferring anything about the weights (coefficients).

#### **Exmplain (sens+spec)/2**

I presented this in a more complicated way than was neccessary. It turns out that the formula is equivalent to the "total percentage correct". I initially set it up that way incase I wanted to penalize false positives or negatives more. I had a multivariate course last year that did this. I never ended up doing that so I will eliminate that metric and just represent it as percentage correct.

#### **Why move 60/40 to 50/50?**

Only because the initial aggregate data I created had very few observations so I was just trying to have more data to train on. There was no real scientific reason for this. I may cut this exploratory section out entirely.

#### **Less on interpreting nnet weights**

Agreed. I have pretty much concluded that trying to extract and interpret weights on large nueral nets is very tricky and not very helpful.


#### **Reduce or cut material on initial analysis and aggregated data**?

Agreed.
